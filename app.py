import os
import subprocess
from PIL import Image
import pytesseract
from transformers import MarianMTModel, MarianTokenizer
from langdetect import detect
import gradio as gr

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Tesseract –∏ —è–∑—ã–∫–æ–≤—ã—Ö –ø–∞–∫–µ—Ç–æ–≤
if not os.path.exists("/usr/bin/tesseract"):
    subprocess.run(["apt-get", "update"])
    subprocess.run([
        "apt-get", "install", "-y",
        "tesseract-ocr", "tesseract-ocr-rus", "tesseract-ocr-spa"
    ])

pytesseract.pytesseract.tesseract_cmd = "/usr/bin/tesseract"

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π
model_ru_es_name = "Helsinki-NLP/opus-mt-ru-es"
model_es_ru_name = "Helsinki-NLP/opus-mt-es-ru"

tokenizer_ru_es = MarianTokenizer.from_pretrained(model_ru_es_name)
model_ru_es = MarianMTModel.from_pretrained(model_ru_es_name)

tokenizer_es_ru = MarianTokenizer.from_pretrained(model_es_ru_name)
model_es_ru = MarianMTModel.from_pretrained(model_es_ru_name)

# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —á–∞—Å—Ç–∏
def split_text(text, max_length=500):
    sentences = text.split('. ')
    chunks = []
    current_chunk = ""
    
    for sentence in sentences:
        if len(current_chunk + sentence) > max_length:
            chunks.append(current_chunk)
            current_chunk = sentence
        else:
            current_chunk += (sentence + '. ')
    
    if current_chunk:
        chunks.append(current_chunk)
    
    return chunks

# –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–ø–µ—Ä–µ–≤–æ–¥ –≤ —á/–±)
def preprocess_image(image):
    gray_image = image.convert('L')
    binarized_image = gray_image.point(lambda p: p > 128 and 255)
    return binarized_image

# –ü–µ—Ä–µ–≤–æ–¥ —Ç–µ–∫—Å—Ç–∞
def translate_text(text, direction):
    if not text.strip():
        return "–û—à–∏–±–∫–∞: –≤–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞."
    if len(text) > 500:
        return "–û—à–∏–±–∫–∞: —Ç–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π (–º–∞–∫—Å–∏–º—É–º 500 —Å–∏–º–≤–æ–ª–æ–≤)."

    if direction == "–ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ":
        lang = detect(text)
        if lang == "ru":
            direction = "–†—É—Å—Å–∫–∏–π ‚Üí –ò—Å–ø–∞–Ω—Å–∫–∏–π"
        elif lang == "es":
            direction = "–ò—Å–ø–∞–Ω—Å–∫–∏–π ‚Üí –†—É—Å—Å–∫–∏–π"
        else:
            return "–û—à–∏–±–∫–∞: –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ —Ä—É—Å—Å–∫–∏–π –∏ –∏—Å–ø–∞–Ω—Å–∫–∏–π —è–∑—ã–∫–∏."

    if direction == "–†—É—Å—Å–∫–∏–π ‚Üí –ò—Å–ø–∞–Ω—Å–∫–∏–π":
        tokenizer = tokenizer_ru_es
        model = model_ru_es
    elif direction == "–ò—Å–ø–∞–Ω—Å–∫–∏–π ‚Üí –†—É—Å—Å–∫–∏–π":
        tokenizer = tokenizer_es_ru
        model = model_es_ru
    else:
        return "–û—à–∏–±–∫–∞: –Ω–µ–≤–µ—Ä–Ω–æ–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–µ—Ä–µ–≤–æ–¥–∞."

    inputs = tokenizer(text, return_tensors="pt")
    translated_tokens = model.generate(**inputs)
    translation = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]
    return translation

# OCR + –ø–µ—Ä–µ–≤–æ–¥
def ocr_and_translate(image, direction):
    try:
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        preprocessed_image = preprocess_image(image)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç
        extracted_text = pytesseract.image_to_string(preprocessed_image, lang="rus+spa")
        
        # –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –∏ –ø–µ—Ä–µ–≤–æ–¥–∏–º
        text_parts = split_text(extracted_text)
        translated_parts = [translate_text(part, direction) for part in text_parts]
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        final_translation = ' '.join(translated_parts)
        return extracted_text.strip(), final_translation
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {e}", ""

# –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å Gradio
with gr.Blocks(title="–ü–µ—Ä–µ–≤–æ–¥—á–∏–∫ RU ‚Üî ES —Å OCR") as app:
    gr.Markdown("## üá∑üá∫ –ü–µ—Ä–µ–≤–æ–¥ —Ç–µ–∫—Å—Ç–∞ –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π üá™üá∏")

    with gr.Tab("üìù –¢–µ–∫—Å—Ç–æ–≤—ã–π –ø–µ—Ä–µ–≤–æ–¥"):
        with gr.Row():
            with gr.Column():
                text_input = gr.Textbox(lines=5, label="–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç")
                direction_text = gr.Radio(
                    ["–ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ", "–†—É—Å—Å–∫–∏–π ‚Üí –ò—Å–ø–∞–Ω—Å–∫–∏–π", "–ò—Å–ø–∞–Ω—Å–∫–∏–π ‚Üí –†—É—Å—Å–∫–∏–π"],
                    value="–ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ",
                    label="–ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–µ—Ä–µ–≤–æ–¥–∞"
                )
                btn_text = gr.Button("–ü–µ—Ä–µ–≤–µ—Å—Ç–∏")
            with gr.Column():
                output_text = gr.Textbox(lines=5, label="–ü–µ—Ä–µ–≤–µ–¥—ë–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç")

        btn_text.click(fn=translate_text, inputs=[text_input, direction_text], outputs=output_text)

    with gr.Tab("üñºÔ∏è –ü–µ—Ä–µ–≤–æ–¥ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"):
        with gr.Row():
            with gr.Column():
                image_input = gr.Image(type="pil", label="–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
                direction_image = gr.Radio(
                    ["–ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ", "–†—É—Å—Å–∫–∏–π ‚Üí –ò—Å–ø–∞–Ω—Å–∫–∏–π", "–ò—Å–ø–∞–Ω—Å–∫–∏–π ‚Üí –†—É—Å—Å–∫–∏–π"],
                    value="–ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ",
                    label="–ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–µ—Ä–µ–≤–æ–¥–∞"
                )
                btn_image = gr.Button("–†–∞—Å–ø–æ–∑–Ω–∞—Ç—å –∏ –ø–µ—Ä–µ–≤–µ—Å—Ç–∏")
            with gr.Column():
                extracted_box = gr.Textbox(lines=5, label="–†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç")
                translated_box = gr.Textbox(lines=5, label="–ü–µ—Ä–µ–≤–µ–¥—ë–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç")

        btn_image.click(
            fn=ocr_and_translate,
            inputs=[image_input, direction_image],
            outputs=[extracted_box, translated_box]
        )

app.launch()
